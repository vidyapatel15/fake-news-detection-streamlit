# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10RJVW_5znShjBiSFICFac-lz15zLg66i

# **MINI PROJECT01:-**

> Add blockquote

Fake News Detection Using Machine Learning & NLP
"""

import streamlit as st
import pickle
import re


import pandas as pd

# Load datasets


# Add labels
fake['label'] = 0  # Fake news
real['label'] = 1  # Real news

# Combine datasets
data = pd.concat([fake, real])
data = data.sample(frac=1).reset_index(drop=True)  # Shuffle

# Explore
print(data.head())
print(data.shape)
print(data['label'].value_counts())

print(data.isnull().sum())
data = data.dropna()  # Drop rows with missing values

import nltk
from nltk.corpus import stopwords
import string

nltk.download('stopwords')
stop_words = stopwords.words('english')

def preprocess(text):
    text = text.lower()  # lowercase
    text = ''.join([c for c in text if c not in string.punctuation])  # remove punctuation
    text = ' '.join([word for word in text.split() if word not in stop_words])  # remove stopwords
    return text

data['clean_text'] = data['text'].apply(preprocess)

"""Split Data

Goal: Separate data into training and testing sets.
"""

from sklearn.model_selection import train_test_split

X = data['clean_text']
y = data['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Convert Text to Numbers"""

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_df=0.7, stop_words='english')
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

"""Train the Model
Use Logistic Regression (simple & effective for text classification).
"""

from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X_train_tfidf, y_train)

"""Make Predictions & Evaluate"""

from sklearn.metrics import accuracy_score, classification_report

y_pred = model.predict(X_test_tfidf)

# Evaluate
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""Save Model
For reuse or deployment:
"""

import pickle

# Save model
pickle.dump(model, open('fake_news_model.pkl', 'wb'))
# Save vectorizer
pickle.dump(vectorizer, open('tfidf_vectorizer.pkl', 'wb'))

# Load
# model = pickle.load(open('fake_news_model.pkl', 'rb'))
# vectorizer = pickle.load(open('tfidf_vectorizer.pkl', 'rb'))



"""Deployment"""



import streamlit as st
import pickle
import re

# Load model and vectorizer
model = pickle.load(open("fake_news_model.pkl", "rb"))
vectorizer = pickle.load(open("tfidf_vectorizer.pkl", "rb"))

# Text preprocessing
def preprocess(text):
    text = text.lower()
    text = re.sub(r'\W', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text

# Streamlit app
st.set_page_config(page_title="Fake News Detector", layout="centered")

st.title("üì∞ Fake News Detection App")
st.markdown("Detect whether the news you entered is **Real** or **Fake** using AI!")

user_input = st.text_area("Enter news content below üëá", height=200)

if st.button("Predict"):
    if user_input.strip() == "":
        st.warning("‚ö†Ô∏è Please enter some news text.")
    else:
        clean_text = preprocess(user_input)
        vectorized_input = vectorizer.transform([clean_text])
        prediction = model.predict(vectorized_input)[0]

        if prediction == 1:
            st.success("‚úÖ This looks like *Real News*!")
        else:
            st.error("üö® This might be *Fake News*!")

st.markdown("---")
st.markdown("Made with ‚ù§Ô∏è using Streamlit and Machine Learning")
